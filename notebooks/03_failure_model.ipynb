{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the prediction model creation portion of my basketball prediction project. This will be the last notebook in the step to having a complete prediction model with manually scraped and pruned data. In the future, I will need to create the failure model that will be able to take these predictions and use a confidence interval to flag a team as a fail if they lose too many games and not failed if they win enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulatiom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# data preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "\n",
    "# result metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# internal imports\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.model import build_preprocessor, build_elasticnet, build_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season           Team  GP          W          L   WIN%        Min  \\\n",
      "0    2016  Atlanta Hawks  82  48.000000  34.000000  0.585  48.400000   \n",
      "1    2017  Atlanta Hawks  82  43.000000  39.000000  0.524  48.500000   \n",
      "2    2018  Atlanta Hawks  82  24.000000  58.000000  0.293  48.100000   \n",
      "3    2019  Atlanta Hawks  82  29.000000  53.000000  0.354  48.400000   \n",
      "4    2020  Atlanta Hawks  67  24.477612  57.522388  0.299  59.480597   \n",
      "\n",
      "          PTS        FGM         FGA  ...  Yw/Franch  YOverall  CareerW  \\\n",
      "0  102.800000  38.600000   84.400000  ...          3         3      146   \n",
      "1  103.200000  38.100000   84.400000  ...          4         4      189   \n",
      "2  103.400000  38.200000   85.500000  ...          5         5      213   \n",
      "3  113.300000  41.400000   91.800000  ...          1         1       29   \n",
      "4  136.829851  49.689552  110.883582  ...          2         2       49   \n",
      "\n",
      "   CareerL  CareerW%  FirstRoundPicks  SecondRoundPicks  Coach_Count  \\\n",
      "0      100     0.593         1.000000          2.000000            1   \n",
      "1      139     0.576         1.000000          2.000000            1   \n",
      "2      197     0.520         3.000000          1.000000            1   \n",
      "3       53     0.354         2.000000          1.000000            1   \n",
      "4      100     0.329         1.223881          1.223881            1   \n",
      "\n",
      "       Payroll      NWins  \n",
      "0   71661760.0  43.000000  \n",
      "1   96315163.0  24.000000  \n",
      "2   99992696.0  29.000000  \n",
      "3   79180081.0  24.477612  \n",
      "4  110702618.0  46.694444  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "master_df = pd.read_csv(\"/Users/trustanprice/Desktop/Personal/Basketball-Predictions/data/raw/master-stats/master_df.csv\")\n",
    "print(master_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create the training and testing data, making the training data 2016-2023 seasons (8 seasons) and the testing data 2024/2025 seasons (2 seasons). I am doing it like this because I am predicting for the seasons to come; therefore, I am trying to replicate the traditional 80/20 split while making it a time-based split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (260, 57)\n",
      "Test shape: (68, 57)\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "master_test = master_df[master_df[\"Season\"].isin([2024, 2025])]\n",
    "master_train = master_df[~master_df[\"Season\"].isin([2024, 2025])]\n",
    "\n",
    "print(\"Train shape:\", master_train.shape)\n",
    "print(\"Test shape:\", master_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric features (continuous or counts)\n",
    "numeric_features = [\n",
    "    \"GP\", \"W\", \"L\", \"WIN%\", \"Min\", \"PTS\", \"FGM\", \"FGA\", \"FG%\",\n",
    "    \"3PM\", \"3PA\", \"3P%\", \"FTM\", \"FTA\", \"FT%\", \"OREB\", \"DREB\",\n",
    "    \"REB\", \"AST\", \"TOV\", \"STL\", \"BLK\", \"BLKA\", \"PF\", \"PFD\",\n",
    "    \"PLUS_MINUS\", \"Home_W\", \"Home_L\", \"Road_W\", \"Road_L\",\n",
    "    \"E_W\", \"E_L\", \"W_W\", \"W_L\", \"Pre-ASG_W\", \"Pre-ASG_L\",\n",
    "    \"Post-ASG_W\", \"Post-ASG_L\", \"SOS\", \"Yw/Franch\", \"YOverall\",\n",
    "    \"CareerW\", \"CareerL\", \"CareerW%\", \"FirstRoundPicks\",\"SecondRoundPicks\", \"Coach_Count\", \"Payroll\",\n",
    "    \n",
    "    # Player-aggregated features\n",
    "    \"avg_age\", \"avg_pts_top10\", \"avg_production_score\", \"injury_rate\"\n",
    "]\n",
    "\n",
    "# Categorical features (labels, identifiers, strings)\n",
    "categorical_features = [\n",
    "    \"Season\"\n",
    "]\n",
    "\n",
    "# Define target column (predict next season’s wins)\n",
    "target_column = \"NWins\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training data ---\n",
    "X_train = master_train.drop(columns=[\"NWins\"])   # drop target column\n",
    "y_train = master_train[\"NWins\"]                  # target = next season wins\n",
    "\n",
    "# --- Testing data ---\n",
    "X_test = master_test.drop(columns=[\"NWins\"])     # drop target column\n",
    "y_test = master_test[\"NWins\"]                    # target = next season wins (NaN for 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in my training and testing data, I will now utilize elastic net for feature selection because of the amount of predictors my original dataset has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "# build preprocessor for reduced features\n",
    "preprocessor = build_preprocessor(numeric_features, categorical_features)\n",
    "\n",
    "# choose a model\n",
    "elasticnet_model = build_elasticnet(preprocessor, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature  Coefficient\n",
      "25            PLUS_MINUS     2.463480\n",
      "2                      L    -1.642310\n",
      "1                      W     1.641432\n",
      "3                   WIN%     1.622578\n",
      "38                   SOS    -0.250511\n",
      "27                Home_L    -0.201869\n",
      "44       FirstRoundPicks    -0.198625\n",
      "26                Home_W     0.173738\n",
      "39             Yw/Franch    -0.000000\n",
      "42               CareerL    -0.000000\n",
      "41               CareerW    -0.000000\n",
      "40              YOverall    -0.000000\n",
      "0                     GP    -0.000000\n",
      "37            Post-ASG_L     0.000000\n",
      "36            Post-ASG_W    -0.000000\n",
      "35             Pre-ASG_L    -0.000000\n",
      "43              CareerW%     0.000000\n",
      "45      SecondRoundPicks     0.000000\n",
      "33                   W_L     0.000000\n",
      "46           Coach_Count    -0.000000\n",
      "47               Payroll     0.000000\n",
      "48               avg_age    -0.000000\n",
      "49         avg_pts_top10    -0.000000\n",
      "50  avg_production_score     0.000000\n",
      "51           injury_rate    -0.000000\n",
      "52           Season_2017     0.000000\n",
      "53           Season_2018    -0.000000\n",
      "54           Season_2019    -0.000000\n",
      "55           Season_2020     0.000000\n",
      "56           Season_2021     0.000000\n"
     ]
    }
   ],
   "source": [
    "# --- Get feature importances (coefficients) ---\n",
    "best_pipeline = elasticnet_model.best_estimator_\n",
    "\n",
    "# 1. Get one-hot encoder feature names\n",
    "cat_ohe = best_pipeline.named_steps['columntransformer'] \\\n",
    "    .named_transformers_['pipeline-2'] \\\n",
    "    .named_steps['onehotencoder'] \\\n",
    "    .get_feature_names_out(categorical_features)\n",
    "\n",
    "# 2. Combine numeric + categorical feature names\n",
    "all_features = numeric_features + list(cat_ohe)\n",
    "\n",
    "# 3. Get coefficients\n",
    "coefficients = best_pipeline.named_steps['elasticnet'].coef_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": all_features,\n",
    "    \"Coefficient\": coefficients\n",
    "}).sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "\n",
    "print(feature_importance.head(30))  # top 30 features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elastic net model has made all of the insignificant predictors coefficients zero so that they do not affect the final outcome of the prediction. As we can see from these results, the predictors left after feature selection are:\n",
    "- PLUS_MINUS\n",
    "- L\n",
    "- W\n",
    "- WIN%\n",
    "- SOS\n",
    "- Home_L\n",
    "- FirstRoundPicks\n",
    "- Home_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only non-zero features ---\n",
    "important_features = [\n",
    "    f for f, c in zip(all_features, coefficients) if abs(c) > 1e-6\n",
    "]\n",
    "\n",
    "# Step 3: Reduce train/test sets ---\n",
    "X_train_reduced = X_train[important_features].copy()\n",
    "X_test_reduced = X_test[important_features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I’ve saved the important features, I will run the KNN model using the function in src/model.py, which contains a hyperparameterized KNN pipeline fitted and processed with GridSearchCV. I set it up this way as a best practice: after first running the Elastic Net model to identify and reduce the predictors, I can now apply a stronger model without excessive computation time, since it runs only on the most accurate and viable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    }
   ],
   "source": [
    "# get reduced features from your selection step\n",
    "reduced_numeric_features = [col for col in X_train_reduced.columns if col in numeric_features]\n",
    "reduced_categorical_features = [col for col in X_train_reduced.columns if col in categorical_features]\n",
    "\n",
    "preprocessor_reduced = build_preprocessor(reduced_numeric_features, reduced_categorical_features)\n",
    "\n",
    "knn_model = build_knn(preprocessor_reduced, X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This marks the current end of the ML Model portion of this notebook, the rest will be geared towards understanding the results of the model (accuracy, predictive power, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will test the predictive power with the 2024 NBA Season as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 → 2024 Predictions\n",
      "                      Team  NWins_2023true  Pred_NWins\n",
      "0            Atlanta Hawks       39.333333   39.333229\n",
      "1           Boston Celtics       64.000000   50.402542\n",
      "2            Brooklyn Nets       38.500000   44.994055\n",
      "3        Charlotte Hornets       21.000000   32.868216\n",
      "4            Chicago Bulls       39.000000   42.201844\n",
      "5      Cleveland Cavaliers       48.000000   46.450984\n",
      "6         Dallas Mavericks       50.000000   41.580628\n",
      "7           Denver Nuggets       57.000000   46.978181\n",
      "8          Detroit Pistons       14.000000   29.210934\n",
      "9    Golden State Warriors       46.000000   39.139384\n",
      "10         Houston Rockets       41.000000   43.738006\n",
      "11          Indiana Pacers       47.000000   44.850759\n",
      "12    Los Angeles Clippers       51.000000   42.528739\n",
      "13      Los Angeles Lakers       47.000000   43.749361\n",
      "14       Memphis Grizzlies       27.000000   30.028467\n",
      "15              Miami Heat       46.000000   45.538259\n",
      "16         Milwaukee Bucks       49.000000   47.299314\n",
      "17  Minnesota Timberwolves       56.000000   46.682961\n",
      "18    New Orleans Pelicans       49.000000   48.228760\n",
      "19         New York Knicks       50.000000   42.799771\n",
      "20   Oklahoma City Thunder       57.000000   48.819186\n",
      "21           Orlando Magic       47.000000   44.744524\n",
      "22      Philadelphia 76ers       47.000000   49.114965\n",
      "23            Phoenix Suns       49.000000   49.267708\n",
      "24  Portland Trail Blazers       21.000000   25.851331\n",
      "25        Sacramento Kings       46.000000   44.351156\n",
      "26       San Antonio Spurs       22.000000   26.668864\n",
      "27         Toronto Raptors       25.000000   34.131996\n",
      "28               Utah Jazz       31.000000   31.830397\n",
      "29      Washington Wizards       15.000000   26.615481\n",
      "Total normalized wins: 1230\n",
      "RMSE: 6.879709995691488 MAE: 5.395928619714832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b8/k6v1k2b945jddf5qjvdvfqwh0000gn/T/ipykernel_16772/2245516765.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  master_test[\"Pred_NWins\"] = knn_model.predict(X_test)\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data (2024)\n",
    "master_test[\"Pred_NWins\"] = knn_model.predict(X_test)\n",
    "\n",
    "total_required_wins = (82 / 2) * 30  # = 1230\n",
    "\n",
    "# --- Compare 2023 → 2024 ---\n",
    "eval_2024 = master_test[master_test[\"Season\"] == 2024].copy()\n",
    "eval_2024 = eval_2024.groupby(\"Team\", as_index=False)[\"Pred_NWins\"].mean()\n",
    "\n",
    "# Normalize 2024 predictions\n",
    "pred_sum_2024 = eval_2024[\"Pred_NWins\"].sum()\n",
    "scaling_factor_2024 = total_required_wins / pred_sum_2024\n",
    "eval_2024[\"Pred_NWins\"] = eval_2024[\"Pred_NWins\"] * scaling_factor_2024\n",
    "\n",
    "train_2023 = (\n",
    "    master_train[master_train[\"Season\"] == 2023]\n",
    "    .groupby(\"Team\", as_index=False)[\"NWins\"].mean()\n",
    "    .rename(columns={\"NWins\": \"NWins_2023true\"})\n",
    ")\n",
    "\n",
    "eval_2024 = eval_2024.merge(train_2023, on=\"Team\")\n",
    "eval_2024 = eval_2024[[\"Team\", \"NWins_2023true\", \"Pred_NWins\"]]\n",
    "\n",
    "rmse_2024 = np.sqrt(mean_squared_error(eval_2024[\"NWins_2023true\"], eval_2024[\"Pred_NWins\"]))\n",
    "mae_2024 = mean_absolute_error(eval_2024[\"NWins_2023true\"], eval_2024[\"Pred_NWins\"])\n",
    "\n",
    "print(\"2023 → 2024 Predictions\")\n",
    "print(eval_2024)\n",
    "print(\"Total normalized wins:\", round(eval_2024[\"Pred_NWins\"].sum()))\n",
    "print(\"RMSE:\", rmse_2024, \"MAE:\", mae_2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will make the predictions for the 2025-2026 NBA Season, making sure to scale it so that there are the correct amount of wins for league as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b8/k6v1k2b945jddf5qjvdvfqwh0000gn/T/ipykernel_16772/1436839067.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  master_test[\"Pred_NWins\"] = knn_model.predict(X_test)\n"
     ]
    }
   ],
   "source": [
    "# get the predictions\n",
    "master_test[\"Pred_NWins\"] = knn_model.predict(X_test)\n",
    "\n",
    "results = master_test[[\"Season\", \"Team\", \"W\", \"Pred_NWins\"] + important_features]\n",
    "results_2025 = results[results[\"Season\"] == 2025].copy()\n",
    "results_2025 = results_2025.drop_duplicates(subset=[\"Team\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Season                    Team     W  Pred_NWins     W     L   WIN%  \\\n",
      "0     2025           Atlanta Hawks  40.0        35.0  40.0  42.0  0.488   \n",
      "1     2025          Boston Celtics  61.0        50.0  61.0  21.0  0.744   \n",
      "2     2025           Brooklyn Nets  26.0        31.0  26.0  56.0  0.317   \n",
      "3     2025       Charlotte Hornets  19.0        31.0  19.0  63.0  0.232   \n",
      "4     2025           Chicago Bulls  39.0        40.0  39.0  43.0  0.476   \n",
      "5     2025     Cleveland Cavaliers  64.0        56.0  64.0  18.0  0.780   \n",
      "6     2025        Dallas Mavericks  39.0        43.0  39.0  43.0  0.476   \n",
      "7     2025          Denver Nuggets  50.0        42.0  50.0  32.0  0.610   \n",
      "8     2025         Detroit Pistons  44.0        47.0  44.0  38.0  0.537   \n",
      "9     2025   Golden State Warriors  48.0        41.0  48.0  34.0  0.585   \n",
      "10    2025         Houston Rockets  52.0        49.0  52.0  30.0  0.634   \n",
      "11    2025          Indiana Pacers  50.0        48.0  50.0  32.0  0.610   \n",
      "12    2025    Los Angeles Clippers  50.0        47.0  50.0  32.0  0.610   \n",
      "13    2025      Los Angeles Lakers  50.0        44.0  50.0  32.0  0.610   \n",
      "14    2025       Memphis Grizzlies  48.0        50.0  48.0  34.0  0.585   \n",
      "15    2025              Miami Heat  37.0        41.0  37.0  45.0  0.451   \n",
      "16    2025         Milwaukee Bucks  48.0        44.0  48.0  34.0  0.585   \n",
      "17    2025  Minnesota Timberwolves  49.0        50.0  49.0  33.0  0.598   \n",
      "18    2025    New Orleans Pelicans  21.0        27.0  21.0  61.0  0.256   \n",
      "19    2025         New York Knicks  51.0        45.0  51.0  31.0  0.622   \n",
      "20    2025   Oklahoma City Thunder  68.0        49.0  68.0  14.0  0.829   \n",
      "21    2025           Orlando Magic  41.0        41.0  41.0  41.0  0.500   \n",
      "22    2025      Philadelphia 76ers  24.0        34.0  24.0  58.0  0.293   \n",
      "23    2025            Phoenix Suns  36.0        38.0  36.0  46.0  0.439   \n",
      "24    2025  Portland Trail Blazers  36.0        37.0  36.0  46.0  0.439   \n",
      "25    2025        Sacramento Kings  40.0        47.0  40.0  42.0  0.488   \n",
      "26    2025       San Antonio Spurs  34.0        33.0  34.0  48.0  0.415   \n",
      "27    2025         Toronto Raptors  30.0        37.0  30.0  52.0  0.366   \n",
      "28    2025               Utah Jazz  17.0        26.0  17.0  65.0  0.207   \n",
      "29    2025      Washington Wizards  18.0        27.0  18.0  64.0  0.220   \n",
      "\n",
      "    PLUS_MINUS  Home_W  Home_L       SOS  FirstRoundPicks  \n",
      "0         -1.1    21.0    19.0  0.495012              2.0  \n",
      "1          9.1    28.0    13.0  0.479110              1.0  \n",
      "2         -7.1    29.0    12.0  0.507207              4.0  \n",
      "3         -9.1    29.0    12.0  0.504085              1.0  \n",
      "4         -1.6    18.0    23.0  0.495756              1.0  \n",
      "5          9.5    34.0     7.0  0.482854              0.0  \n",
      "6         -1.2    22.0    18.0  0.509256              1.0  \n",
      "7          3.9    26.0    15.0  0.498866              0.0  \n",
      "8          1.9    22.0    19.0  0.499610              0.0  \n",
      "9          3.3    24.0    17.0  0.504390              0.0  \n",
      "10         4.5    29.0    12.0  0.507939              1.0  \n",
      "11         2.2    29.0    12.0  0.485488              1.0  \n",
      "12         4.7    30.0    11.0  0.503024              1.0  \n",
      "13         1.2    31.0    10.0  0.499159              0.0  \n",
      "14         4.9    26.0    15.0  0.497537              1.0  \n",
      "15         0.6    19.0    22.0  0.493256              1.0  \n",
      "16         2.5    28.0    14.0  0.492805              0.0  \n",
      "17         5.0    25.0    16.0  0.503012              1.0  \n",
      "18        -9.4    14.0    27.0  0.520585              1.0  \n",
      "19         4.1    27.0    14.0  0.488927              0.0  \n",
      "20        12.9    36.0     6.0  0.492037              2.0  \n",
      "21        -0.1    22.0    19.0  0.486695              1.0  \n",
      "22        -6.2    29.0    12.0  0.503037              1.0  \n",
      "23        -3.0    24.0    17.0  0.508244              1.0  \n",
      "24        -3.0    22.0    19.0  0.504829              1.0  \n",
      "25         0.5    20.0    21.0  0.501098              0.0  \n",
      "26        -2.8    20.0    21.0  0.505402              2.0  \n",
      "27        -4.3    18.0    23.0  0.500817              1.0  \n",
      "28        -9.3    31.0    10.0  0.521793              2.0  \n",
      "29       -12.4     8.0    33.0  0.510171              2.0  \n",
      "Check total: 1230.0\n"
     ]
    }
   ],
   "source": [
    "total_required_wins = (82 / 2) * 30\n",
    "pred_sum = results_2025[\"Pred_NWins\"].sum()\n",
    "scaling_factor = total_required_wins / pred_sum\n",
    "\n",
    "# replace Pred_NWins with normalized version\n",
    "results_2025[\"Pred_NWins\"] = (results_2025[\"Pred_NWins\"] * scaling_factor).round()\n",
    "\n",
    "print(results_2025)\n",
    "print(\"Check total:\", results_2025[\"Pred_NWins\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as normal CSV\n",
    "results_2025.to_csv(\"/Users/trustanprice/Desktop/Personal/Basketball-Predictions/data/raw/master-stats/results_2025.csv\", index=False)\n",
    "\n",
    "# Save as gzip-compressed CSV\n",
    "results_2025.to_csv(\"/Users/trustanprice/Desktop/Personal/Basketball-Predictions/data/processed/master-data/results_2025.csv.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I currently have a lot to work on left for the predictive power of this model; however, I am happy with where I have gotten in the span of less than a week! In the future, I will look to try and use Strength of Schedule as a better predictive element; to explain, currently the model is predicting off of previous seasons SOS when it should be using the next seasons strength of schedule calculated by how good the team was in the previous year.\n",
    "\n",
    "Looking back, I am happy I was able to tune the model as much as I was, but when I come back I will do much more feature and data processing engineering. I am excited for whats to come and hopefully anyone reading this is able to enjoy the project for what it is currently!\n",
    "\n",
    "#### LeBron James is the GOAT"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
