{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the prediction model creation portion of my basketball prediction project. This will be the last notebook in the step to having a complete prediction model with manually scraped and pruned data. In the future, I will need to create the failure model that will be able to take these predictions and use a confidence interval to flag a team as a fail if they lose too many games and not failed if they win enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'build_elasticnet' from 'src.model' (/Users/trustanprice/Desktop/Personal/Basketball-Predictions/src/model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[234]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     22\u001b[39m sys.path.append(os.path.abspath(\u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_preprocessor, build_elasticnet, build_knn\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'build_elasticnet' from 'src.model' (/Users/trustanprice/Desktop/Personal/Basketball-Predictions/src/model.py)"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# data preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "\n",
    "# src imports\n",
    "%reset -f\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.model import build_preprocessor, build_elasticnet, build_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trustanprice/Desktop/Personal/Basketball-Predictions/src/model.py\n",
      "['OneHotEncoder', 'RobustScaler', 'SimpleImputer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'build_preprocessor', 'make_column_transformer', 'make_pipeline']\n"
     ]
    }
   ],
   "source": [
    "import src.model\n",
    "print(src.model.__file__)\n",
    "print(dir(src.model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "master_df = pd.read_csv(\"/Users/trustanprice/Desktop/Personal/Basketball-Predictions/data/raw/master-stats/master_df.csv\")\n",
    "print(master_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create the training and testing data, making the training data 2016-2023 seasons (8 seasons) and the testing data 2024/2025 seasons (2 seasons). I am doing it like this because I am predicting for the seasons to come; therefore, I am trying to replicate the traditional 80/20 split while making it a time-based split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "master_test = master_df[master_df[\"Season\"].isin([2024, 2025])]\n",
    "master_train = master_df[~master_df[\"Season\"].isin([2024, 2025])]\n",
    "\n",
    "print(\"Train shape:\", master_train.shape)\n",
    "print(\"Test shape:\", master_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric features (continuous or counts)\n",
    "numeric_features = [\n",
    "    \"GP\", \"W\", \"L\", \"WIN%\", \"Min\", \"PTS\", \"FGM\", \"FGA\", \"FG%\",\n",
    "    \"3PM\", \"3PA\", \"3P%\", \"FTM\", \"FTA\", \"FT%\", \"OREB\", \"DREB\",\n",
    "    \"REB\", \"AST\", \"TOV\", \"STL\", \"BLK\", \"BLKA\", \"PF\", \"PFD\",\n",
    "    \"PLUS_MINUS\", \"Home_W\", \"Home_L\", \"Road_W\", \"Road_L\",\n",
    "    \"E_W\", \"E_L\", \"W_W\", \"W_L\", \"Pre-ASG_W\", \"Pre-ASG_L\",\n",
    "    \"Post-ASG_W\", \"Post-ASG_L\", \"SOS\", \"Yw/Franch\", \"YOverall\",\n",
    "    \"CareerW\", \"CareerL\", \"CareerW%\", \"Pk\", \"Coach_Count\", \"Payroll\",\n",
    "    \n",
    "    # Player-aggregated features\n",
    "    \"avg_age\", \"avg_pts_top10\", \"avg_production_score\", \"injury_rate\"\n",
    "]\n",
    "\n",
    "# Categorical features (labels, identifiers, strings)\n",
    "categorical_features = [\n",
    "    \"Season\"\n",
    "]\n",
    "\n",
    "# Define target column (predict next seasonâ€™s wins)\n",
    "target_column = \"NWins\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training data ---\n",
    "X_train = master_train.drop(columns=[\"NWins\"])   # drop target column\n",
    "y_train = master_train[\"NWins\"]                  # target = next season wins\n",
    "\n",
    "# --- Testing data ---\n",
    "X_test = master_test.drop(columns=[\"NWins\"])     # drop target column\n",
    "y_test = master_test[\"NWins\"]                    # target = next season wins (NaN for 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build preprocessor for reduced features\n",
    "preprocessor = build_preprocessor(numeric_features, categorical_features)\n",
    "\n",
    "# choose a model\n",
    "model = build_elasticnet(preprocessor)  \n",
    "\n",
    "# train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Get feature importances (coefficients) ---\n",
    "best_pipeline = model.best_estimator_\n",
    "\n",
    "# 1. Get one-hot encoder feature names\n",
    "cat_ohe = best_pipeline.named_steps['columntransformer'] \\\n",
    "    .named_transformers_['pipeline-2'] \\\n",
    "    .named_steps['onehotencoder'] \\\n",
    "    .get_feature_names_out(categorical_features)\n",
    "\n",
    "# 2. Combine numeric + categorical feature names\n",
    "all_features = numeric_features + list(cat_ohe)\n",
    "\n",
    "# 3. Get coefficients\n",
    "coefficients = best_pipeline.named_steps['elasticnet'].coef_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": all_features,\n",
    "    \"Coefficient\": coefficients\n",
    "}).sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "\n",
    "print(feature_importance.head(30))  # top 15 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Keep only non-zero features ---\n",
    "important_features = [\n",
    "    f for f, c in zip(all_features, coefficients) if abs(c) > 1e-6\n",
    "]\n",
    "\n",
    "print(\"Selected features:\", important_features)\n",
    "\n",
    "# --- Step 3: Reduce train/test sets ---\n",
    "X_train_reduced = X_train[important_features].copy()\n",
    "X_test_reduced = X_test[important_features].copy()\n",
    "\n",
    "print(\"Reduced train shape:\", X_train_reduced.shape)\n",
    "print(\"Reduced test shape:\", X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get reduced features from your selection step\n",
    "reduced_numeric_features = [col for col in X_train_reduced.columns if col in numeric_features]\n",
    "reduced_categorical_features = [col for col in X_train_reduced.columns if col in categorical_features]\n",
    "\n",
    "preprocessor_reduced = build_preprocessor(reduced_numeric_features, reduced_categorical_features)\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'kneighborsregressor__n_neighbors': [3, 5, 7, 10], \n",
    "    'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "    'kneighborsregressor__metric': ['euclidean', 'manhattan', 'minkowski'], \n",
    "    'kneighborsregressor__p': [1, 2]\n",
    "}\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor_reduced,\n",
    "    knn,\n",
    ")\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=10, \n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report model metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
