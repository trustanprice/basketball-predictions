{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the prediction model creation portion of my basketball prediction project. This will be the last notebook in the step to having a complete prediction model with manually scraped and pruned data. In the future, I will need to create the failure model that will be able to take these predictions and use a confidence interval to flag a team as a fail if they lose too many games and not failed if they win enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# data preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "\n",
    "# src imports\n",
    "from src.model import build_preprocessor, build_elasticnet, build_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season                   Team  GP     W     L   WIN%   Min    PTS   FGM  \\\n",
      "0    2025  Oklahoma City Thunder  82  68.0  14.0  0.829  48.1  120.5  44.6   \n",
      "1    2025  Oklahoma City Thunder  82  68.0  14.0  0.829  48.1  120.5  44.6   \n",
      "2    2025  Oklahoma City Thunder  82  68.0  14.0  0.829  48.1  120.5  44.6   \n",
      "3    2025    Cleveland Cavaliers  82  64.0  18.0  0.780  48.2  121.9  44.5   \n",
      "4    2025    Cleveland Cavaliers  82  64.0  18.0  0.780  48.2  121.9  44.5   \n",
      "\n",
      "    FGA  ...            Coach  Yw/Franch  YOverall  CareerW  CareerL  \\\n",
      "0  92.7  ...  Mark Daigneault          5         5      211      189   \n",
      "1  92.7  ...  Mark Daigneault          5         5      211      189   \n",
      "2  92.7  ...  Mark Daigneault          5         5      211      189   \n",
      "3  90.8  ...   Kenny Atkinson          1         5      182      208   \n",
      "4  90.8  ...   Kenny Atkinson          1         5      182      208   \n",
      "\n",
      "   CareerW%  Pk  Coach_Count      Payroll  NWins  \n",
      "0     0.528  15            1  166418720.0    NaN  \n",
      "1     0.528  24            1  166418720.0    NaN  \n",
      "2     0.528  44            1  166418720.0    NaN  \n",
      "3     0.467  49            1  165110486.0    NaN  \n",
      "4     0.467  58            1  165110486.0    NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "master_df = pd.read_csv(\"/Users/trustanprice/Desktop/Personal/Basketball-Predictions/data/raw/master-stats/master_df.csv\")\n",
    "print(master_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create the training and testing data, making the training data 2016-2023 seasons (8 seasons) and the testing data 2024/2025 seasons (2 seasons). I am doing it like this because I am predicting for the seasons to come; therefore, I am trying to replicate the traditional 80/20 split while making it a time-based split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (515, 56)\n",
      "Test shape: (132, 56)\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "master_test = master_df[master_df[\"Season\"].isin([2024, 2025])]\n",
    "master_train = master_df[~master_df[\"Season\"].isin([2024, 2025])]\n",
    "\n",
    "print(\"Train shape:\", master_train.shape)\n",
    "print(\"Test shape:\", master_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric features (continuous or counts)\n",
    "numeric_features = [\n",
    "    \"GP\", \"W\", \"L\", \"WIN%\", \"Min\", \"PTS\", \"FGM\", \"FGA\", \"FG%\",\n",
    "    \"3PM\", \"3PA\", \"3P%\", \"FTM\", \"FTA\", \"FT%\", \"OREB\", \"DREB\",\n",
    "    \"REB\", \"AST\", \"TOV\", \"STL\", \"BLK\", \"BLKA\", \"PF\", \"PFD\",\n",
    "    \"PLUS_MINUS\", \"Home_W\", \"Home_L\", \"Road_W\", \"Road_L\",\n",
    "    \"E_W\", \"E_L\", \"W_W\", \"W_L\", \"Pre-ASG_W\", \"Pre-ASG_L\",\n",
    "    \"Post-ASG_W\", \"Post-ASG_L\", \"SOS\", \"Yw/Franch\", \"YOverall\",\n",
    "    \"CareerW\", \"CareerL\", \"CareerW%\", \"Pk\", \"Coach_Count\", \"Payroll\",\n",
    "    \n",
    "    # Player-aggregated features\n",
    "    \"avg_age\", \"avg_pts_top10\", \"avg_production_score\", \"injury_rate\"\n",
    "]\n",
    "\n",
    "# Categorical features (labels, identifiers, strings)\n",
    "categorical_features = [\n",
    "    \"Season\"\n",
    "]\n",
    "\n",
    "# Define target column (predict next seasonâ€™s wins)\n",
    "target_column = \"NWins\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training data ---\n",
    "X_train = master_train.drop(columns=[\"NWins\"])   # drop target column\n",
    "y_train = master_train[\"NWins\"]                  # target = next season wins\n",
    "\n",
    "# --- Testing data ---\n",
    "X_test = master_test.drop(columns=[\"NWins\"])     # drop target column\n",
    "y_test = master_test[\"NWins\"]                    # target = next season wins (NaN for 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "# build preprocessor for reduced features\n",
    "preprocessor = build_preprocessor(numeric_features, categorical_features)\n",
    "\n",
    "# choose a model\n",
    "elasticnet_model = build_elasticnet(preprocessor, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature  Coefficient\n",
      "25            PLUS_MINUS     3.011835\n",
      "38                   SOS    -1.342478\n",
      "2                      L    -1.220410\n",
      "1                      W     1.219661\n",
      "3                   WIN%     1.219532\n",
      "20                   STL     0.565105\n",
      "4                    Min     0.333147\n",
      "12                   FTM     0.150562\n",
      "27                Home_L    -0.074596\n",
      "43              CareerW%    -0.000000\n",
      "37            Post-ASG_L     0.000000\n",
      "36            Post-ASG_W    -0.000000\n",
      "35             Pre-ASG_L    -0.000000\n",
      "39             Yw/Franch    -0.000000\n",
      "40              YOverall     0.000000\n",
      "41               CareerW    -0.000000\n",
      "42               CareerL     0.000000\n",
      "0                     GP    -0.000000\n",
      "46               Payroll    -0.000000\n",
      "44                    Pk     0.000000\n",
      "45           Coach_Count    -0.000000\n",
      "33                   W_L    -0.000000\n",
      "47               avg_age    -0.000000\n",
      "48         avg_pts_top10    -0.000000\n",
      "49  avg_production_score     0.000000\n",
      "50           injury_rate    -0.000000\n",
      "51           Season_2017     0.000000\n",
      "52           Season_2018     0.000000\n",
      "53           Season_2019    -0.000000\n",
      "54           Season_2020     0.000000\n"
     ]
    }
   ],
   "source": [
    "# --- Get feature importances (coefficients) ---\n",
    "best_pipeline = elasticnet_model.best_estimator_\n",
    "\n",
    "# 1. Get one-hot encoder feature names\n",
    "cat_ohe = best_pipeline.named_steps['columntransformer'] \\\n",
    "    .named_transformers_['pipeline-2'] \\\n",
    "    .named_steps['onehotencoder'] \\\n",
    "    .get_feature_names_out(categorical_features)\n",
    "\n",
    "# 2. Combine numeric + categorical feature names\n",
    "all_features = numeric_features + list(cat_ohe)\n",
    "\n",
    "# 3. Get coefficients\n",
    "coefficients = best_pipeline.named_steps['elasticnet'].coef_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": all_features,\n",
    "    \"Coefficient\": coefficients\n",
    "}).sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "\n",
    "print(feature_importance.head(30))  # top 15 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['W', 'L', 'WIN%', 'Min', 'FTM', 'STL', 'PLUS_MINUS', 'Home_L', 'SOS']\n",
      "Reduced train shape: (515, 9)\n",
      "Reduced test shape: (132, 9)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Keep only non-zero features ---\n",
    "important_features = [\n",
    "    f for f, c in zip(all_features, coefficients) if abs(c) > 1e-6\n",
    "]\n",
    "\n",
    "print(\"Selected features:\", important_features)\n",
    "\n",
    "# --- Step 3: Reduce train/test sets ---\n",
    "X_train_reduced = X_train[important_features].copy()\n",
    "X_test_reduced = X_test[important_features].copy()\n",
    "\n",
    "print(\"Reduced train shape:\", X_train_reduced.shape)\n",
    "print(\"Reduced test shape:\", X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get reduced features from your selection step\n",
    "reduced_numeric_features = [col for col in X_train_reduced.columns if col in numeric_features]\n",
    "reduced_categorical_features = [col for col in X_train_reduced.columns if col in categorical_features]\n",
    "\n",
    "preprocessor_reduced = build_preprocessor(reduced_numeric_features, reduced_categorical_features)\n",
    "\n",
    "knn_model = build_knn(preprocessor_reduced, X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report model metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
